{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevtrivedi/pgd-dsai/blob/main/AudioEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ONK22hBBXBW",
        "outputId": "c151ba91-5cf8-4571-8f44-5d80eaea15e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: Mount gdrive and create two file paths My drive/PML/AudioEncoding with file Sample1.mp3 and sample2.mp3\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths\n",
        "audio_dir = \"/content/drive/My Drive/PML/AudioEncoding\"\n",
        "file1_path = os.path.join(audio_dir, \"sample1.mp3\")\n",
        "file2_path = os.path.join(audio_dir, \"sample2.mp3\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: pip install librosa numpy matplotlib scipy scikit-learn soundfile\n",
        "\n",
        "!pip install librosa numpy matplotlib scipy scikit-learn soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3lsx3JrD8r8",
        "outputId": "2e014598-a677-4c9c-b983-9290a7d6df88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def load_audio_files(file_paths):\n",
        "  \"\"\"Loads audio files into a list of NumPy arrays.\n",
        "\n",
        "  Args:\n",
        "    file_paths: A list of file paths to audio files.\n",
        "\n",
        "  Returns:\n",
        "    A list of NumPy arrays, where each element is an audio file loaded as a NumPy array.\n",
        "    Returns None if any error occurs during file loading.\n",
        "  \"\"\"\n",
        "  audio_data = []\n",
        "  for file_path in file_paths:\n",
        "    try:\n",
        "      # Load audio file using librosa\n",
        "      y, sr = librosa.load(file_path, sr=None)  # sr=None preserves original sample rate\n",
        "      audio_data.append(y)\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading file {file_path}: {e}\")\n",
        "      return None  # Return None to indicate an error\n",
        "  # Instead of creating numpy array return a list of audio data\n",
        "  return audio_data\n",
        "\n",
        "\n",
        "# Example usage (assuming file1_path and file2_path are defined)\n",
        "file_paths = [file1_path, file2_path]\n",
        "audio_array = load_audio_files(file_paths)\n",
        "\n",
        "if audio_array is not None:\n",
        "  print(\"Audio files loaded successfully.\")\n",
        "  #print(f\"Shape of the audio array: {audio_array.shape}\") # This won't work now\n",
        "  print(f\"Number of audio files loaded: {len(audio_array)}\")\n",
        "  print(f\"Shape of the first audio file: {audio_array[0].shape}\")\n",
        "  print(f\"Shape of the second audio file: {audio_array[1].shape}\")\n",
        "  # Now you can work with the audio_array (as a list)\n",
        "else:\n",
        "  print(\"Error loading audio files. Check file paths and permissions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I88oE1KEC4V",
        "outputId": "669752ad-6e30-4e62-bcd9-c3d62785c94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio files loaded successfully.\n",
            "Number of audio files loaded: 2\n",
            "Shape of the first audio file: (5384326,)\n",
            "Shape of the second audio file: (9585510,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Do the Pre-emphasis Filter\n",
        "\n",
        "def pre_emphasis_filter(audio_data, alpha=0.97):\n",
        "  \"\"\"Applies pre-emphasis filter to audio data.\n",
        "\n",
        "  Args:\n",
        "    audio_data: A NumPy array representing the audio signal.\n",
        "    alpha: The pre-emphasis coefficient (default is 0.97).\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array representing the filtered audio signal.\n",
        "  \"\"\"\n",
        "  if not isinstance(audio_data, np.ndarray):\n",
        "    print(\"Error: Input audio_data must be a NumPy array.\")\n",
        "    return None  # Handle the case where audio_data is not a NumPy array\n",
        "\n",
        "  emphasized_audio = np.append(audio_data[0], audio_data[1:] - alpha * audio_data[:-1])\n",
        "  return emphasized_audio\n",
        "\n",
        "\n",
        "# Assuming audio_array is a list of audio signals (NumPy arrays)\n",
        "if audio_array is not None:\n",
        "  filtered_audio_signals = []\n",
        "  for audio in audio_array:\n",
        "    filtered_audio = pre_emphasis_filter(audio)\n",
        "    if filtered_audio is not None:\n",
        "        filtered_audio_signals.append(filtered_audio)\n",
        "    else:\n",
        "        print(\"Skipping pre-emphasis for an invalid audio signal.\")\n",
        "\n",
        "  if filtered_audio_signals:\n",
        "    print(\"Pre-emphasis applied successfully.\")\n",
        "    print(f\"Shape of the first filtered audio file: {filtered_audio_signals[0].shape}\")\n",
        "    print(f\"Shape of the second filtered audio file: {filtered_audio_signals[1].shape}\")\n",
        "    # Now you can work with the filtered_audio_signals\n",
        "  else:\n",
        "    print(\"No valid audio signals to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJH3ROXeEo1y",
        "outputId": "1a52f480-d9bf-452e-bc5f-c2223a9cf2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-emphasis applied successfully.\n",
            "Shape of the first filtered audio file: (5384326,)\n",
            "Shape of the second filtered audio file: (9585510,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frame the Signal and Apply Windowing and can be skipped"
      ],
      "metadata": {
        "id": "PWkqAuPBNdyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Frame the Signal and Apply Windowing\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def frame_audio(audio, frame_length, hop_length):\n",
        "  \"\"\"Frames the audio signal.\n",
        "\n",
        "  Args:\n",
        "    audio: A NumPy array representing the audio signal.\n",
        "    frame_length: The length of each frame in samples.\n",
        "    hop_length: The hop length between frames in samples.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array of shape (num_frames, frame_length) representing the framed audio.\n",
        "  \"\"\"\n",
        "  num_frames = 1 + (len(audio) - frame_length) // hop_length\n",
        "  frames = np.zeros((num_frames, frame_length))\n",
        "  for i in range(num_frames):\n",
        "    frames[i] = audio[i * hop_length:i * hop_length + frame_length]\n",
        "  return frames\n",
        "\n",
        "def apply_window(frames, window_type='hamming'):\n",
        "  \"\"\"Applies a window function to each frame.\n",
        "\n",
        "  Args:\n",
        "    frames: A NumPy array of shape (num_frames, frame_length) representing the framed audio.\n",
        "    window_type: The type of window function to apply ('hamming', 'hanning', etc.).\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array of shape (num_frames, frame_length) representing the windowed frames.\n",
        "  \"\"\"\n",
        "  window = getattr(np, window_type)(frames.shape[1])\n",
        "  windowed_frames = frames * window\n",
        "  return windowed_frames\n",
        "\n",
        "# Example usage with the first filtered audio signal:\n",
        "if filtered_audio_signals:\n",
        "  frame_length = 2048  # Adjust as needed\n",
        "  hop_length = 512  # Adjust as needed\n",
        "  first_audio_frames = frame_audio(filtered_audio_signals[0], frame_length, hop_length)\n",
        "\n",
        "  windowed_frames = apply_window(first_audio_frames)\n",
        "\n",
        "  print(\"Framing and windowing applied successfully.\")\n",
        "  print(f\"Shape of the first audio frames: {first_audio_frames.shape}\")\n",
        "  print(f\"Shape of the windowed frames: {windowed_frames.shape}\")\n",
        "else:\n",
        "  print(\"No valid filtered audio signals to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgFmLsC8FLcL",
        "outputId": "00d1b7d7-b522-4a67-977e-8089717a925d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Framing and windowing applied successfully.\n",
            "Shape of the first audio frames: (10513, 2048)\n",
            "Shape of the windowed frames: (10513, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Extract MFCC Features\n",
        "\n",
        "def extract_mfccs(windowed_frames, sr, n_mfcc=20):\n",
        "    \"\"\"Extracts MFCC features from windowed audio frames.\n",
        "\n",
        "    Args:\n",
        "        windowed_frames: A NumPy array of shape (num_frames, frame_length) representing the windowed audio frames.\n",
        "        sr: The sample rate of the audio signal.\n",
        "        n_mfcc: The number of MFCCs to extract (default is 20).\n",
        "\n",
        "    Returns:\n",
        "        A NumPy array of shape (num_frames, n_mfcc) representing the MFCC features.\n",
        "    \"\"\"\n",
        "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(librosa.stft(windowed_frames.flatten(), n_fft=2048)), n_mfcc=n_mfcc, sr=sr)\n",
        "    return mfccs\n",
        "\n",
        "# Example usage with the windowed frames:\n",
        "if filtered_audio_signals:\n",
        "    sr = 22050  # Replace with the actual sample rate if known\n",
        "    mfccs = extract_mfccs(windowed_frames, sr=sr)\n",
        "\n",
        "    print(\"MFCCs extracted successfully.\")\n",
        "    print(f\"Shape of the MFCCs: {mfccs.shape}\")\n",
        "else:\n",
        "    print(\"No valid windowed frames to process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bpTcZW1FfzX",
        "outputId": "6b880cba-3a2a-4d7d-eae2-7745a64a577c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-449ac0058dff>:14: UserWarning: power_to_db was called on complex input so phase information will be discarded. To suppress this warning, call power_to_db(np.abs(D)**2) instead.\n",
            "  mfccs = librosa.feature.mfcc(S=librosa.power_to_db(librosa.stft(windowed_frames.flatten(), n_fft=2048)), n_mfcc=n_mfcc, sr=sr)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCCs extracted successfully.\n",
            "Shape of the MFCCs: (20, 42053)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Print the freatures head after converting into dataframes\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'mfccs' is the NumPy array containing the MFCC features\n",
        "if 'mfccs' in locals():\n",
        "    # Convert MFCCs to a DataFrame\n",
        "    mfccs_df = pd.DataFrame(mfccs.T)  # Transpose to have frames as rows\n",
        "\n",
        "    # Print the head of the DataFrame\n",
        "    print(mfccs_df.head())\n",
        "else:\n",
        "    print(\"mfccs variable not found. Please ensure the MFCC extraction code has been executed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mamjrZ4tHQnh",
        "outputId": "ac388add-ff0c-4fff-c7e4-1083904fb810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0           1          2          3          4          5   \\\n",
            "0 -800.099994  346.779010  57.017684 -18.100890  -8.872198 -11.257400   \n",
            "1 -725.522540  429.350888  -6.554317 -14.626890  20.103321 -23.773131   \n",
            "2 -752.854691  488.010365 -37.354213 -10.981864  34.226774 -28.949057   \n",
            "3 -695.523674  343.011851  30.742115  -5.646907  20.640031  -2.153186   \n",
            "4 -708.530001  268.682894  49.933304  -1.528434   5.986457  -2.751555   \n",
            "\n",
            "          6          7          8          9          10         11  \\\n",
            "0   4.545213   3.128058 -18.592855 -20.052229  -6.435541  10.278706   \n",
            "1   1.147689  -8.395159 -22.879504   3.245004 -10.003518  -3.129512   \n",
            "2   2.533276 -16.780498 -22.315548  17.361293 -14.435732  -9.474195   \n",
            "3 -11.699178 -16.473867  -7.107546   6.716165 -10.788779  -6.242123   \n",
            "4 -10.477893 -14.535877  -6.549513   1.583280  -5.991547   0.059249   \n",
            "\n",
            "          12         13         14         15         16         17  \\\n",
            "0   5.066026 -26.236538 -18.487093  19.741057  11.433748 -15.442807   \n",
            "1  20.697359 -23.000948 -27.013790  25.901199   6.562415 -16.355524   \n",
            "2  30.639222 -16.703965 -26.721949  29.136379  -3.007756 -10.520064   \n",
            "3  14.578271  -8.577360 -16.100566  11.296120   6.978394 -13.265970   \n",
            "4   8.797458  -8.924305 -14.589676   3.556737   4.290506  -8.843156   \n",
            "\n",
            "          18        19  \n",
            "0  -8.290908  5.498582  \n",
            "1  -6.131362 -3.788710  \n",
            "2  -5.515537 -7.834487  \n",
            "3 -10.996252 -0.634723  \n",
            "4 -12.170474 -3.691387  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Save the features into csv\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "mfccs_df.to_csv('/content/drive/My Drive/PML/Audio Encoding/mfcc_features.csv', index=False)\n",
        "print(\"MFCC features saved to CSV file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxUA2ABvIfEG",
        "outputId": "761d5212-62d5-430c-918f-40850421794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCC features saved to CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def extract_stats(mfcc_frames,n_mfcc=20):\n",
        "    \"\"\"\n",
        "    Extracts MFCCs from an audio file and calculates statistical summaries\n",
        "    for each coefficient.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file.\n",
        "        n_mfcc (int): Number of MFCC coefficients to extract.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - mfcc_frames (numpy.ndarray): The MFCC frame sequence (T x n_mfcc).\n",
        "            - mfcc_stats (pandas.Series): A Series containing the statistical\n",
        "              summary for each MFCC coefficient. Returns None if loading fails.\n",
        "    \"\"\"\n",
        "        # Create a fixed length feature vector by creating statistical summaries of each MFCC\n",
        "        # This will create and concatenate 20 statistical values calculated\n",
        "        # It should be noted that the number of columns of MFCC will vary depending\n",
        "        # But the feature vector will be : 20 original coefficients + (20 x number_of_stats)\n",
        "        # In the following case, the feature vector will have 20 + 20 x 9 = 200 values\n",
        "    mfcc_stats = {}\n",
        "    for i in range(n_mfcc):\n",
        "        coefficient = mfcc_frames[i, :]\n",
        "        mfcc_stats[f'mfcc_{i}_mean'] = np.mean(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_min'] = np.min(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_max'] = np.max(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_25_percentile'] = np.percentile(coefficient, 25)\n",
        "        mfcc_stats[f'mfcc_{i}_median'] = np.median(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_75_percentile'] = np.percentile(coefficient, 75)\n",
        "        mfcc_stats[f'mfcc_{i}_std'] = np.std(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_skew'] = skew(coefficient)\n",
        "        mfcc_stats[f'mfcc_{i}_kurtosis'] = kurtosis(coefficient)\n",
        "\n",
        "    return pd.Series(mfcc_stats)\n",
        "\n",
        "\n",
        "\n",
        "mfcc_feature_vector = extract_stats(mfccs, n_mfcc=20)\n",
        "\n",
        "if mfcc_feature_vector is not None:\n",
        "    print(\"\\nExtracted MFCC Feature Vector:\")\n",
        "    print(mfcc_feature_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-egc5V6H5uN",
        "outputId": "26939f1d-db40-4939-b39a-6f2e9a71b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted MFCC Feature Vector:\n",
            "mfcc_0_mean              -636.547758\n",
            "mfcc_0_min              -1577.476206\n",
            "mfcc_0_max               -159.525734\n",
            "mfcc_0_25_percentile     -749.264205\n",
            "mfcc_0_median            -637.756064\n",
            "                            ...     \n",
            "mfcc_19_median             -2.807818\n",
            "mfcc_19_75_percentile       6.678061\n",
            "mfcc_19_std                14.844871\n",
            "mfcc_19_skew                0.418035\n",
            "mfcc_19_kurtosis            1.235179\n",
            "Length: 180, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a function which adds in dataframe and Extracted MFCC Feature Vector\n",
        "\n",
        "def add_to_dataframe(df, feature_vector):\n",
        "    \"\"\"Adds a feature vector to a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: The DataFrame to add the feature vector to.\n",
        "        feature_vector: A pandas Series representing the feature vector.\n",
        "\n",
        "    Returns:\n",
        "        A new DataFrame with the feature vector added as a new row,\n",
        "        or None if there's an error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert the Series to a DataFrame to enable concatenation\n",
        "        feature_df = pd.DataFrame([feature_vector])\n",
        "\n",
        "        # Concatenate the feature DataFrame with the existing DataFrame\n",
        "        new_df = pd.concat([df, feature_df], ignore_index=True)\n",
        "        return new_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding feature vector to DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fv4PgtvcOxBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a empty dataframe using mfcc_feature_vector\n",
        "\n",
        "mfcc_feature_vector_df = pd.DataFrame(columns=mfcc_feature_vector.index)\n",
        "\n",
        "mfcc_feature_vector_df  = add_to_dataframe(mfcc_feature_vector_df, mfcc_feature_vector)\n",
        "\n",
        "if mfcc_feature_vector_df is not None:\n",
        "    print(\"\\nDataFrame after adding feature vector:\")\n",
        "    print(mfcc_feature_vector_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm8bRiAqIGHJ",
        "outputId": "6a14a528-adbc-40fe-d89e-07d6d3d10564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after adding feature vector:\n",
            "   mfcc_0_mean   mfcc_0_min  mfcc_0_max  mfcc_0_25_percentile  mfcc_0_median  \\\n",
            "0  -636.547758 -1577.476206 -159.525734           -749.264205    -637.756064   \n",
            "\n",
            "   mfcc_0_75_percentile  mfcc_0_std  mfcc_0_skew  mfcc_0_kurtosis  \\\n",
            "0           -499.522957  200.531308    -0.821985         2.172317   \n",
            "\n",
            "   mfcc_1_mean  ...  mfcc_18_kurtosis  mfcc_19_mean  mfcc_19_min  mfcc_19_max  \\\n",
            "0   331.271729  ...          1.158693     -1.711279   -82.482551    78.539049   \n",
            "\n",
            "   mfcc_19_25_percentile  mfcc_19_median  mfcc_19_75_percentile  mfcc_19_std  \\\n",
            "0             -11.151117       -2.807818               6.678061    14.844871   \n",
            "\n",
            "   mfcc_19_skew  mfcc_19_kurtosis  \n",
            "0      0.418035          1.235179  \n",
            "\n",
            "[1 rows x 180 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-58813e228e32>:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  new_df = pd.concat([df, feature_df], ignore_index=True)\n"
          ]
        }
      ]
    }
  ]
}